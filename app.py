"""
Map â†” Satellite Converter - Streamlit æ‡‰ç”¨ç¨‹å¼
æ”¯æ´äº’å‹•å¼åœ°åœ–é¸æ“‡å’Œ Google Maps æˆªåœ–è½‰æ›

ä½¿ç”¨ CycleGAN æ¨¡å‹é€²è¡Œè¡›æ˜Ÿåœ–åƒèˆ‡åœ°åœ–ä¹‹é–“çš„è½‰æ›
åŸºæ–¼ pytorch-CycleGAN-and-pix2pix å°ˆæ¡ˆ
"""

import streamlit as st
import torch
import torch.nn as nn
from PIL import Image
import numpy as np
import urllib.request
import os
from io import BytesIO

# =====================================================
# CycleGAN ResNet Generator æ¨¡å‹æ¶æ§‹
# =====================================================

class ResnetBlock(nn.Module):
    """ResNet Block for CycleGAN"""
    def __init__(self, dim, use_bias=True):
        super(ResnetBlock, self).__init__()
        self.conv_block = nn.Sequential(
            nn.ReflectionPad2d(1),
            nn.Conv2d(dim, dim, kernel_size=3, padding=0, bias=use_bias),
            nn.BatchNorm2d(dim, affine=False, track_running_stats=True),
            nn.ReLU(True),
            nn.ReflectionPad2d(1),
            nn.Conv2d(dim, dim, kernel_size=3, padding=0, bias=use_bias),
            nn.BatchNorm2d(dim, affine=False, track_running_stats=True)
        )

    def forward(self, x):
        return x + self.conv_block(x)


class ResnetGenerator(nn.Module):
    """ResNet-based Generator for CycleGAN (èˆ‡é è¨“ç·´æ¨¡å‹ç›¸å®¹)"""
    def __init__(self, input_nc=3, output_nc=3, ngf=64, n_blocks=9):
        super(ResnetGenerator, self).__init__()
        
        use_bias = True
        
        # Initial conv block
        model = [
            nn.ReflectionPad2d(3),
            nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=use_bias),
            nn.BatchNorm2d(ngf, affine=False, track_running_stats=True),
            nn.ReLU(True)
        ]

        # Downsampling
        n_downsampling = 2
        for i in range(n_downsampling):
            mult = 2 ** i
            model += [
                nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),
                nn.BatchNorm2d(ngf * mult * 2, affine=False, track_running_stats=True),
                nn.ReLU(True)
            ]

        # ResNet blocks
        mult = 2 ** n_downsampling
        for i in range(n_blocks):
            model += [ResnetBlock(ngf * mult, use_bias=use_bias)]

        # Upsampling
        for i in range(n_downsampling):
            mult = 2 ** (n_downsampling - i)
            model += [
                nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),
                                   kernel_size=3, stride=2, padding=1, output_padding=1, bias=use_bias),
                nn.BatchNorm2d(int(ngf * mult / 2), affine=False, track_running_stats=True),
                nn.ReLU(True)
            ]
        
        # Output conv
        model += [
            nn.ReflectionPad2d(3),
            nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0, bias=use_bias),
            nn.Tanh()
        ]

        self.model = nn.Sequential(*model)
    
    def forward(self, x):
        return self.model(x)


# =====================================================
# å·¥å…·å‡½å¼
# =====================================================

def download_cyclegan_model(model_name, save_dir="checkpoints"):
    """ä¸‹è¼‰ CycleGAN é è¨“ç·´æ¨¡å‹"""
    os.makedirs(save_dir, exist_ok=True)
    model_path = os.path.join(save_dir, f"{model_name}_cyclegan.pth")
    
    if not os.path.exists(model_path):
        url = f"http://efrosgans.eecs.berkeley.edu/cyclegan/pretrained_models/{model_name}.pth"
        st.info(f"æ­£åœ¨ä¸‹è¼‰ CycleGAN æ¨¡å‹: {model_name}...")
        
        try:
            urllib.request.urlretrieve(url, model_path)
            st.success(f"æ¨¡å‹ä¸‹è¼‰å®Œæˆï¼")
        except Exception as e:
            st.error(f"ä¸‹è¼‰å¤±æ•—: {e}")
            return None
    
    return model_path


@st.cache_resource
def load_cyclegan_model(model_path, _device_str):
    """è¼‰å…¥ CycleGAN ç”Ÿæˆå™¨æ¨¡å‹"""
    device = torch.device(_device_str)
    
    # å»ºç«‹èˆ‡é è¨“ç·´æ¨¡å‹ç›¸å®¹çš„ ResNet generator
    model = ResnetGenerator(input_nc=3, output_nc=3, ngf=64, n_blocks=9)
    
    try:
        state_dict = torch.load(model_path, map_location=device, weights_only=False)
    except:
        state_dict = torch.load(model_path, map_location=device)
    
    model.load_state_dict(state_dict)
    model.to(device)
    model.eval()
    return model, device


def preprocess_image(image, target_size=256):
    """é è™•ç†è¼¸å…¥åœ–åƒ"""
    # ä¿æŒæ­£æ–¹å½¢æ¯”ä¾‹
    w, h = image.size
    size = min(w, h)
    left = (w - size) // 2
    top = (h - size) // 2
    image = image.crop((left, top, left + size, top + size))
    
    # èª¿æ•´å¤§å°
    image = image.resize((target_size, target_size), Image.Resampling.LANCZOS)
    
    # è½‰æ›ç‚º numpy é™£åˆ—
    img_array = np.array(image).astype(np.float32)
    
    # æ­£è¦åŒ–åˆ° [-1, 1]
    img_array = (img_array / 255.0 - 0.5) / 0.5
    
    # è½‰æ›ç‚º PyTorch tensor [B, C, H, W]
    img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).unsqueeze(0)
    
    return img_tensor


def postprocess_image(tensor):
    """å¾Œè™•ç†è¼¸å‡º tensor ç‚ºåœ–åƒ"""
    img = tensor.cpu().detach().squeeze(0).permute(1, 2, 0).numpy()
    img = (img * 0.5 + 0.5) * 255.0
    img = np.clip(img, 0, 255).astype(np.uint8)
    return Image.fromarray(img)


def run_inference(model, input_image, device, size=256):
    """åŸ·è¡Œæ¨è«–"""
    with torch.no_grad():
        input_tensor = preprocess_image(input_image, size).to(device)
        output_tensor = model(input_tensor)
        output_image = postprocess_image(output_tensor)
    return output_image


# =====================================================
# Streamlit æ‡‰ç”¨ç¨‹å¼
# =====================================================

def main():
    st.set_page_config(
        page_title="Map â†” Satellite Converter",
        page_icon="ğŸ—ºï¸",
        layout="wide"
    )
    
    st.title("ğŸ—ºï¸ åœ°åœ– â†” è¡›æ˜Ÿåœ–åƒè½‰æ›å™¨")
    st.markdown("""
    ä½¿ç”¨ **CycleGAN** æ·±åº¦å­¸ç¿’æ¨¡å‹é€²è¡Œåœ°åœ–èˆ‡è¡›æ˜Ÿåœ–åƒä¹‹é–“çš„è½‰æ›ã€‚
    
    âœ¨ **ä½¿ç”¨æ–¹å¼**ï¼š
    1. é¸æ“‡è½‰æ›æ–¹å‘
    2. åœ¨äº’å‹•åœ°åœ–ä¸­å°èˆªåˆ°ç›®æ¨™å€åŸŸï¼Œæ“·å–æˆªåœ–
    3. ä¸Šå‚³æˆªåœ–é€²è¡Œ AI è½‰æ›
    """)
    
    st.divider()
    
    # å´é‚Šæ¬„è¨­å®š
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")
        
        # é¸æ“‡è½‰æ›æ–¹å‘
        direction = st.radio(
            "é¸æ“‡è½‰æ›æ–¹å‘",
            ["ğŸ—ºï¸ â†’ ğŸ›°ï¸ åœ°åœ–è½‰è¡›æ˜Ÿ", "ğŸ›°ï¸ â†’ ğŸ—ºï¸ è¡›æ˜Ÿè½‰åœ°åœ–"],
            index=0
        )
        
        if "åœ°åœ–è½‰è¡›æ˜Ÿ" in direction:
            model_name = "map2sat"
            input_type = "åœ°åœ–"
            output_type = "è¡›æ˜Ÿåœ–åƒ"
        else:
            model_name = "sat2map"
            input_type = "è¡›æ˜Ÿåœ–åƒ"
            output_type = "åœ°åœ–"
        
        st.divider()
        
        # åœ–åƒå¤§å°è¨­å®š
        output_size = st.selectbox(
            "è¼¸å‡ºåœ–åƒå¤§å°",
            [256, 512],
            index=0,
            help="è¼ƒå¤§çš„åœ–åƒéœ€è¦æ›´å¤šè™•ç†æ™‚é–“"
        )
        
        # è¨­å‚™é¸æ“‡
        if torch.cuda.is_available():
            device_choice = st.selectbox("é¸æ“‡è£ç½®", ["CUDA (GPU)", "CPU"])
        else:
            st.info("æœªåµæ¸¬åˆ° GPUï¼Œä½¿ç”¨ CPU")
            device_choice = "CPU"
        
        st.divider()
        
        # æ¨¡å‹ç‹€æ…‹
        st.header("ğŸ“¦ æ¨¡å‹ç‹€æ…‹")
        checkpoints_dir = "checkpoints"
        model_path = os.path.join(checkpoints_dir, f"{model_name}_cyclegan.pth")
        
        if os.path.exists(model_path):
            st.success(f"âœ… {model_name} æ¨¡å‹å·²å°±ç·’")
        else:
            st.warning(f"âš ï¸ éœ€è¦ä¸‹è¼‰ {model_name} æ¨¡å‹")
            if st.button(f"ğŸ“¥ ä¸‹è¼‰ {model_name} æ¨¡å‹", use_container_width=True):
                download_cyclegan_model(model_name, checkpoints_dir)
                st.rerun()
        
        st.divider()
        
        # ä½¿ç”¨èªªæ˜
        with st.expander("ğŸ“– ä½¿ç”¨èªªæ˜"):
            st.markdown("""
            1. **é¸æ“‡è½‰æ›æ–¹å‘**
            2. **ç¢ºä¿æ¨¡å‹å·²ä¸‹è¼‰**
            3. **ä½¿ç”¨ç„¡æ¨™ç±¤åœ°åœ–åœ–å±¤**
            4. **æ“·å–åœ°åœ–æˆªåœ–**
            5. **ä¸Šå‚³ä¸¦è½‰æ›**
            
            **å»ºè­°ä½¿ç”¨ï¼š**
            - CartoDB ç„¡æ¨™ç±¤åœ–å±¤
            - Esri/Google è¡›æ˜Ÿåœ–
            """)
    
    # ä¸»è¦å…§å®¹å€ - ä½¿ç”¨ tabs
    tab1, tab2 = st.tabs(["ğŸ—ºï¸ äº’å‹•åœ°åœ–", "â“ ä½¿ç”¨èªªæ˜"])
    
    with tab1:
        st.subheader("ğŸ—ºï¸ äº’å‹•å¼åœ°åœ–")
        st.markdown("""
        ä½¿ç”¨ä¸‹æ–¹çš„äº’å‹•åœ°åœ–å°èˆªåˆ°æ‚¨æƒ³è¦è½‰æ›çš„å€åŸŸï¼Œç„¶å¾Œæ“·å–è¢å¹•æˆªåœ–ä¸¦ä¸Šå‚³ã€‚
        """)
        
        # å˜—è©¦ä½¿ç”¨ Folium
        try:
            import folium
            from streamlit_folium import st_folium
            
            col_map, col_result = st.columns([2, 1])
            
            with col_map:
                # é è¨­ä½ç½®ï¼ˆå°ä¸­èˆˆå¤§ï¼‰
                default_lat = 24.1215
                default_lon = 120.6756
                
                # å»ºç«‹åœ°åœ–
                m = folium.Map(
                    location=[default_lat, default_lon],
                    zoom_start=16,
                    tiles=None
                )
                
                # æ·»åŠ ç„¡æ¨™è¨»åœ°åœ–åœ–å±¤ï¼ˆé¿å…æ–‡å­—å½±éŸ¿æ¨¡å‹ï¼‰
                folium.TileLayer(
                    tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Street_Map/MapServer/tile/{z}/{y}/{x}',
                    attr='Esri',
                    name='Esri è¡—é“åœ°åœ–ï¼ˆå°‘æ¨™è¨»ï¼‰',
                    overlay=False
                ).add_to(m)
                
                folium.TileLayer(
                    tiles='https://{s}.basemaps.cartocdn.com/rastertiles/voyager_nolabels/{z}/{x}/{y}{r}.png',
                    attr='CartoDB',
                    name='CartoDB ç„¡æ¨™ç±¤',
                    overlay=False
                ).add_to(m)
                
                folium.TileLayer(
                    tiles='https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}',
                    attr='Google',
                    name='Google è¡›æ˜Ÿï¼ˆç„¡æ¨™ç±¤ï¼‰',
                    overlay=False
                ).add_to(m)
                
                folium.TileLayer(
                    tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',
                    attr='Esri',
                    name='Esri è¡›æ˜Ÿåœ–',
                    overlay=False
                ).add_to(m)
                
                folium.LayerControl().add_to(m)
                
                # é¡¯ç¤ºåœ°åœ–
                map_data = st_folium(m, width=700, height=500)
                
                st.info("ğŸ’¡ è«‹ä½¿ç”¨ **CartoDB ç„¡æ¨™ç±¤** æˆ– **è¡›æ˜Ÿåœ–** åœ–å±¤ï¼Œé¿å…æ–‡å­—æ¨™è¨»å½±éŸ¿è½‰æ›æ•ˆæœã€‚ä½¿ç”¨ **Win+Shift+S** æ“·å–æˆªåœ–ã€‚")
            
            with col_result:
                st.subheader("ğŸ“¤ ä¸Šå‚³æˆªåœ–")
                
                map_screenshot = st.file_uploader(
                    "ä¸Šå‚³åœ°åœ–æˆªåœ–",
                    type=["jpg", "jpeg", "png"],
                    key="map_screenshot"
                )
                
                if map_screenshot is not None:
                    map_image = Image.open(map_screenshot).convert("RGB")
                    st.image(map_image, caption="æˆªåœ–é è¦½", use_container_width=True)
                    
                    if os.path.exists(model_path):
                        if st.button("ğŸš€ è½‰æ›æˆªåœ–", type="primary", use_container_width=True):
                            with st.spinner("è½‰æ›ä¸­..."):
                                try:
                                    device_str = "cuda" if "CUDA" in device_choice else "cpu"
                                    model, device = load_cyclegan_model(model_path, device_str)
                                    output_image = run_inference(model, map_image, device, output_size)
                                    st.image(output_image, caption="è½‰æ›çµæœ", use_container_width=True)
                                    st.session_state['map_output'] = output_image
                                except Exception as e:
                                    st.error(f"éŒ¯èª¤: {e}")
                        
                        if 'map_output' in st.session_state:
                            buf = BytesIO()
                            st.session_state['map_output'].save(buf, format="PNG")
                            buf.seek(0)
                            st.download_button("ğŸ’¾ ä¸‹è¼‰", data=buf, file_name="converted.png", mime="image/png")
                    else:
                        st.warning("è«‹å…ˆä¸‹è¼‰æ¨¡å‹")
                        
        except ImportError:
            st.warning("ğŸ“¦ éœ€è¦å®‰è£é¡å¤–å¥—ä»¶ä¾†ä½¿ç”¨äº’å‹•åœ°åœ–åŠŸèƒ½")
            st.code("pip install folium streamlit-folium", language="bash")
            
            # å‚™ç”¨æ–¹æ¡ˆï¼šåµŒå…¥å¼åœ°åœ–
            st.markdown("### ğŸ—ºï¸ å‚™ç”¨æ–¹æ¡ˆï¼šåµŒå…¥å¼åœ°åœ–")
            st.markdown("æ‚¨å¯ä»¥åœ¨ä¸‹æ–¹åœ°åœ–ä¸­å°èˆªï¼Œç„¶å¾Œä½¿ç”¨æˆªåœ–å·¥å…·æ“·å–ã€‚")
            
            # åµŒå…¥ OpenStreetMap
            iframe_html = '''
            <iframe 
                width="100%" 
                height="500" 
                frameborder="0" 
                scrolling="no" 
                marginheight="0" 
                marginwidth="0" 
                src="https://www.openstreetmap.org/export/embed.html?bbox=120.6556%2C24.1015%2C120.6956%2C24.1415&amp;layer=mapnik"
                style="border: 1px solid #ccc; border-radius: 8px;">
            </iframe>
            '''
            st.components.v1.html(iframe_html, height=520)
            
            st.info("ğŸ’¡ ä½¿ç”¨ **Win+Shift+S** æ“·å–ä¸Šæ–¹åœ°åœ–å€åŸŸçš„æˆªåœ–")
            
            # ä¸Šå‚³æˆªåœ–
            map_screenshot = st.file_uploader(
                "ä¸Šå‚³åœ°åœ–æˆªåœ–",
                type=["jpg", "jpeg", "png"],
                key="map_screenshot_backup"
            )
            
            if map_screenshot is not None:
                col_a, col_b = st.columns(2)
                with col_a:
                    map_image = Image.open(map_screenshot).convert("RGB")
                    st.image(map_image, caption="è¼¸å…¥æˆªåœ–", use_container_width=True)
                
                with col_b:
                    if os.path.exists(model_path):
                        if st.button("ğŸš€ è½‰æ›", type="primary", use_container_width=True):
                            with st.spinner("è½‰æ›ä¸­..."):
                                try:
                                    device_str = "cuda" if "CUDA" in device_choice else "cpu"
                                    model, device = load_cyclegan_model(model_path, device_str)
                                    output_image = run_inference(model, map_image, device, output_size)
                                    st.image(output_image, caption="è½‰æ›çµæœ", use_container_width=True)
                                except Exception as e:
                                    st.error(f"éŒ¯èª¤: {e}")
                    else:
                        st.warning("è«‹å…ˆä¸‹è¼‰æ¨¡å‹")
    
    with tab2:
        st.markdown("""
        ### ğŸ“¸ å¦‚ä½•æ“·å–åœ°åœ–æˆªåœ–
        
        **æ–¹æ³• 1: ä½¿ç”¨ Google Maps**
        1. é–‹å•Ÿ [Google Maps](https://www.google.com/maps)
        2. åˆ‡æ›åˆ°ã€Œåœ°åœ–ã€æˆ–ã€Œè¡›æ˜Ÿã€æª¢è¦–
        3. ç¸®æ”¾åˆ°æƒ³è¦çš„å€åŸŸ
        4. ä½¿ç”¨æˆªåœ–å·¥å…·æ“·å–ï¼ˆWindows: **Win+Shift+S**ï¼‰
        
        **æ–¹æ³• 2: ä½¿ç”¨ OpenStreetMap**
        1. é–‹å•Ÿ [OpenStreetMap](https://www.openstreetmap.org)
        2. å°èˆªåˆ°ç›®æ¨™å€åŸŸ
        3. æ“·å–è¢å¹•æˆªåœ–
        
        **ğŸ’¡ æç¤º**ï¼šç‚ºäº†æœ€ä½³æ•ˆæœï¼Œå»ºè­°ï¼š
        - ä½¿ç”¨æ­£æ–¹å½¢æˆ–æ¥è¿‘æ­£æ–¹å½¢çš„æˆªåœ–
        - é¿å…åŒ…å« UI å…ƒç´ ï¼ˆæœå°‹æ¡†ã€æŒ‰éˆ•ç­‰ï¼‰
        - é¸æ“‡ zoom level 15-18 çš„ç¯„åœ
        """)
        
        st.divider()
        
        st.markdown("""
        ### ğŸ”¬ é—œæ–¼ CycleGAN æ¨¡å‹
        
        **CycleGAN** æ˜¯ä¸€ç¨®ç”¨æ–¼éé…å°åœ–åƒè½‰æ›çš„æ·±åº¦å­¸ç¿’æ¨¡å‹ã€‚èˆ‡ pix2pix ä¸åŒï¼Œ
        CycleGAN ä¸éœ€è¦åš´æ ¼é…å°çš„è¨“ç·´è³‡æ–™ï¼Œå› æ­¤å°æ–¼ä¸åŒä¾†æºçš„åœ°åœ–æˆªåœ–æœ‰æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚
        
        **ç‚ºä»€éº¼é¸æ“‡ CycleGANï¼Ÿ**
        - âœ… å°å„ç¨®åœ°åœ–é¢¨æ ¼æœ‰è¼ƒå¥½çš„æ³›åŒ–èƒ½åŠ›
        - âœ… ä¸éœ€è¦åš´æ ¼é…å°çš„è¨“ç·´è³‡æ–™
        - âœ… æ”¯æ´é›™å‘è½‰æ›ï¼ˆåœ°åœ–â†”è¡›æ˜Ÿï¼‰
        
        **æ¨¡å‹ä¾†æº**: [pytorch-CycleGAN-and-pix2pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)
        
        ### âš ï¸ æ³¨æ„äº‹é …
        
        1. **è¼¸å…¥åœ–åƒå“è³ª**ï¼šè¼ƒæ¸…æ™°çš„æˆªåœ–æœƒç”¢ç”Ÿè¼ƒå¥½çš„çµæœ
        2. **åœ–åƒæ¯”ä¾‹**ï¼šå»ºè­°ä½¿ç”¨æ­£æ–¹å½¢æˆ–æ¥è¿‘æ­£æ–¹å½¢çš„æˆªåœ–
        3. **ç¸®æ”¾ç´šåˆ¥**ï¼šzoom 15-18 çš„åœ°åœ–æ•ˆæœæœ€ä½³
        4. **é¿å… UI å…ƒç´ **ï¼šæˆªåœ–æ™‚é¿å…åŒ…å«æœå°‹æ¡†ã€æŒ‰éˆ•ç­‰ä»‹é¢å…ƒç´ 
        
        ### ğŸ¯ æœ€ä½³å¯¦è¸
        
        - ä½¿ç”¨ç´”åœ°åœ–è¦–åœ–ï¼Œæ¸›å°‘æ¨™è¨»å’Œåœ–æ¨™
        - é¸æ“‡æœ‰æ˜é¡¯é“è·¯å’Œå»ºç¯‰ç‰©çš„å€åŸŸ
        - ä¿æŒé©ä¸­çš„ç¸®æ”¾ç´šåˆ¥
        """)
    
    # é å°¾
    st.divider()
    st.caption("ğŸ¤– åŸºæ–¼ CycleGAN æ¨¡å‹ | [GitHub](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)")


if __name__ == "__main__":
    main()
